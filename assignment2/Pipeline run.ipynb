{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c939603b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rutger/miniconda3/envs/pynlp/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "2022-09-23 10:37:21.135432: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2022-09-23 10:37:21.135466: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from ml_pipeline import experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa27b533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Running vua_format experiment\n",
      ">> Loading data...\n",
      ">> retrieving train/data instances...\n",
      ">> training pipeline naive_bayes_counts\n",
      ">> testing...\n",
      ">> evaluation...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CAG       0.30      0.43      0.35       555\n",
      "         NAG       0.70      0.52      0.60      1113\n",
      "         NOT       0.46      0.93      0.61       620\n",
      "         OAG       0.43      0.29      0.34       505\n",
      "         OFF       0.34      0.31      0.33       240\n",
      "        hate       0.80      0.10      0.18       239\n",
      "      noHate       0.36      0.03      0.06       239\n",
      "\n",
      "    accuracy                           0.47      3511\n",
      "   macro avg       0.48      0.37      0.35      3511\n",
      "weighted avg       0.51      0.47      0.44      3511\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = experiment.run(\n",
    "    task_name='vua_format',\n",
    "    data_dir='../pynlp/data/dataset1/',\n",
    "    pipeline_name='naive_bayes_counts',\n",
    "    print_predictions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd02725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be020383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gibert_test = pd.read_csv('../pynlp/data/gibert/testData.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0dd6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 <ml_pipeline.preprocessing.Preprocessor object at 0x7f4fa3070cd0>),\n",
       "                ('frm', CountVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90bda4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = res['prep']\n",
    "frm = res['frm']\n",
    "clf = res['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2c19a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = prep.transform(df_gibert_test['Text'])\n",
    "res = frm.transform(res)\n",
    "pred = clf.predict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f87b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gibert_test['Pred'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbabdf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30399453_2</td>\n",
       "      <td>I can give you her Skype and she will answer a...</td>\n",
       "      <td>noHate</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13456898_1</td>\n",
       "      <td>I know exactly what you 're saying , I just ha...</td>\n",
       "      <td>hate</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13605248_8</td>\n",
       "      <td>Norway : 3.3 ( 2001 ) , 3.9 ( 2002 ) , 3.5 ( 2...</td>\n",
       "      <td>noHate</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14101084_1</td>\n",
       "      <td>I used to enter horse competitions until I was...</td>\n",
       "      <td>noHate</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12849464_4</td>\n",
       "      <td>And the sad thing is the white students at tho...</td>\n",
       "      <td>hate</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                                               Text   Label  Pred\n",
       "0  30399453_2  I can give you her Skype and she will answer a...  noHate   NOT\n",
       "1  13456898_1  I know exactly what you 're saying , I just ha...    hate   OFF\n",
       "2  13605248_8  Norway : 3.3 ( 2001 ) , 3.9 ( 2002 ) , 3.5 ( 2...  noHate  hate\n",
       "3  14101084_1  I used to enter horse competitions until I was...  noHate   NAG\n",
       "4  12849464_4  And the sad thing is the white students at tho...    hate   NOT"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gibert_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9791ce",
   "metadata": {},
   "source": [
    "**TODO: Deal with overlapping labels**\n",
    "\n",
    "Need to decide on a single annotation scheme, or modify the training objective somehow.\n",
    "\n",
    "Right now, a model is punished for classifying a message as e.g. `NOT` when the corresponding label is `noHate`.\n",
    "Both of these point at the same thing, namely that the text does not contain any hate speech / offensive language."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
